(self.webpackChunksuperbench_website=self.webpackChunksuperbench_website||[]).push([[6143],{3905:function(e,t,n){"use strict";n.d(t,{Zo:function(){return s},kt:function(){return c}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function p(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},l=Object.keys(e);for(r=0;r<l.length;r++)n=l[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(r=0;r<l.length;r++)n=l[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var m=r.createContext({}),o=function(e){var t=r.useContext(m),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},s=function(e){var t=o(e.components);return r.createElement(m.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,l=e.originalType,m=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),u=o(n),c=a,h=u["".concat(m,".").concat(c)]||u[c]||d[c]||l;return n?r.createElement(h,i(i({ref:t},s),{},{components:n})):r.createElement(h,i({ref:t},s))}));function c(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var l=n.length,i=new Array(l);i[0]=u;var p={};for(var m in t)hasOwnProperty.call(t,m)&&(p[m]=t[m]);p.originalType=e,p.mdxType="string"==typeof e?e:a,i[1]=p;for(var o=2;o<l;o++)i[o]=n[o];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},395:function(e,t,n){"use strict";n.r(t),n.d(t,{frontMatter:function(){return p},contentTitle:function(){return m},metadata:function(){return o},toc:function(){return s},default:function(){return u}});var r=n(2122),a=n(9756),l=(n(7294),n(3905)),i=["components"],p={id:"model-benchmarks"},m="Model Benchmarks",o={unversionedId:"user-tutorial/benchmarks/model-benchmarks",id:"user-tutorial/benchmarks/model-benchmarks",isDocsHomePage:!1,title:"Model Benchmarks",description:"PyTorch Model Benchmarks",source:"@site/../docs/user-tutorial/benchmarks/model-benchmarks.md",sourceDirName:"user-tutorial/benchmarks",slug:"/user-tutorial/benchmarks/model-benchmarks",permalink:"/superbenchmark/docs/user-tutorial/benchmarks/model-benchmarks",editUrl:"https://github.com/microsoft/superbenchmark/edit/main/website/../docs/user-tutorial/benchmarks/model-benchmarks.md",version:"current",frontMatter:{id:"model-benchmarks"},sidebar:"docs",previous:{title:"Micro Benchmarks",permalink:"/superbenchmark/docs/user-tutorial/benchmarks/micro-benchmarks"},next:{title:"Docker Benchmarks",permalink:"/superbenchmark/docs/user-tutorial/benchmarks/docker-benchmarks"}},s=[{value:"PyTorch Model Benchmarks",id:"pytorch-model-benchmarks",children:[{value:"<code>gpt_models</code>",id:"gpt_models",children:[]},{value:"<code>bert_models</code>",id:"bert_models",children:[]},{value:"<code>lstm_models</code>",id:"lstm_models",children:[]},{value:"<code>cnn_models</code>",id:"cnn_models",children:[]}]}],d={toc:s};function u(e){var t=e.components,n=(0,a.Z)(e,i);return(0,l.kt)("wrapper",(0,r.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"model-benchmarks"},"Model Benchmarks"),(0,l.kt)("h2",{id:"pytorch-model-benchmarks"},"PyTorch Model Benchmarks"),(0,l.kt)("h3",{id:"gpt_models"},(0,l.kt)("inlineCode",{parentName:"h3"},"gpt_models")),(0,l.kt)("h4",{id:"introduction"},"Introduction"),(0,l.kt)("p",null,"Run training or inference tasks with single or half precision for GPT models,\nincluding gpt2-small, gpt2-medium, gpt2-large and gpt2-xl.\nThe supported percentiles are 50, 90, 95, 99, and 99.9."),(0,l.kt)("h4",{id:"metrics"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpt_models/pytorch-${model_name}/fp32_train_step_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training step time with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpt_models/pytorch-${model_name}/fp32_train_throughput"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training throughput with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpt",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp32_inference_step_time"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference step time with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpt",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp32_inference_throughput"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference throughput with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpt_models/pytorch-${model_name}/fp16_train_step_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training step time with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpt_models/pytorch-${model_name}/fp16_train_throughput"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training throughput with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpt",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp16_inference_step_time"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference step time with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpt",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp16_inference_throughput"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference throughput with half precision.")))),(0,l.kt)("h3",{id:"bert_models"},(0,l.kt)("inlineCode",{parentName:"h3"},"bert_models")),(0,l.kt)("h4",{id:"introduction-1"},"Introduction"),(0,l.kt)("p",null,"Run training or inference tasks with single or half precision for BERT models, including bert-base and bert-large.\nThe supported percentiles are 50, 90, 95, 99, and 99.9."),(0,l.kt)("h4",{id:"metrics-1"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bert_models/pytorch-${model_name}/fp32_train_step_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training step time with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bert_models/pytorch-${model_name}/fp32_train_throughput"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training throughput with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bert",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp32_inference_step_time"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference step time with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bert",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp32_inference_throughput"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference throughput with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bert_models/pytorch-${model_name}/fp16_train_step_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training step time with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bert_models/pytorch-${model_name}/fp16_train_throughput"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training throughput with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bert",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp16_inference_step_time"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference step time with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"bert",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp16_inference_throughput"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference throughput with half precision.")))),(0,l.kt)("h3",{id:"lstm_models"},(0,l.kt)("inlineCode",{parentName:"h3"},"lstm_models")),(0,l.kt)("h4",{id:"introduction-2"},"Introduction"),(0,l.kt)("p",null,"Run training or inference tasks with single or half precision for one bidirectional LSTM model.\nThe supported percentiles are 50, 90, 95, 99, and 99.9."),(0,l.kt)("h4",{id:"metrics-2"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"lstm_models/pytorch-lstm/fp32_train_step_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training step time with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"lstm_models/pytorch-lstm/fp32_train_throughput"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training throughput with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"lstm",(0,l.kt)("em",{parentName:"td"},"models/pytorch-lstm/fp32_inference_step_time"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference step time with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"lstm",(0,l.kt)("em",{parentName:"td"},"models/pytorch-lstm/fp32_inference_throughput"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference throughput with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"lstm_models/pytorch-lstm/fp16_train_step_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training step time with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"lstm_models/pytorch-lstm/fp16_train_throughput"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The average training throughput with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"lstm",(0,l.kt)("em",{parentName:"td"},"models/pytorch-lstm/fp16_inference_step_time"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference step time with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"lstm",(0,l.kt)("em",{parentName:"td"},"models/pytorch-lstm/fp16_inference_throughput"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference throughput with half precision.")))),(0,l.kt)("h3",{id:"cnn_models"},(0,l.kt)("inlineCode",{parentName:"h3"},"cnn_models")),(0,l.kt)("h4",{id:"introduction-3"},"Introduction"),(0,l.kt)("p",null,"Run training or inference tasks with single or half precision for CNN models listed in\n",(0,l.kt)("a",{parentName:"p",href:"https://pytorch.org/vision/0.8/models.html"},(0,l.kt)("inlineCode",{parentName:"a"},"torchvision.models")),", including:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"resnet: resnet18, resnet34, resnet50, resnet101, resnet152"),(0,l.kt)("li",{parentName:"ul"},"resnext: resnext50_32x4d, resnext101_32x8d"),(0,l.kt)("li",{parentName:"ul"},"wide_resnet: wide_resnet50_2, wide_resnet101_2"),(0,l.kt)("li",{parentName:"ul"},"densenet: densenet121, densenet169, densenet201, densenet161"),(0,l.kt)("li",{parentName:"ul"},"vgg: vgg11, vgg11_bn, vgg13, vgg13_bn, vgg16, vgg16_bn, vgg19_bn, vgg19"),(0,l.kt)("li",{parentName:"ul"},"mnasnet: mnasnet0_5, mnasnet0_75, mnasnet1_0, mnasnet1_3"),(0,l.kt)("li",{parentName:"ul"},"mobilenet: mobilenet_v2"),(0,l.kt)("li",{parentName:"ul"},"shufflenet: shufflenet_v2_x0_5, shufflenet_v2_x1_0, shufflenet_v2_x1_5, shufflenet_v2_x2_0"),(0,l.kt)("li",{parentName:"ul"},"squeezenet: squeezenet1_0, squeezenet1_1"),(0,l.kt)("li",{parentName:"ul"},"others: alexnet, googlenet, inception_v3\nThe supported percentiles are 50, 90, 95, 99, and 99.9.")),(0,l.kt)("h4",{id:"metrics-3"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"cnn_models/pytorch-${model_name}/fp32_train_step_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"Train average step time with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"cnn_models/pytorch-${model_name}/fp32_train_throughput"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"Train average throughput with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"cnn",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp32_inference_step_time"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference step time with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"cnn",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp32_inference_throughput"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference throughput with single precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"cnn_models/pytorch-${model_name}/fp16_train_step_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"Train average step time with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"cnn_models/pytorch-${model_name}/fp16_train_throughput"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"Train average throughput with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"cnn",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp16_inference_step_time"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference step time with half precision.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"cnn",(0,l.kt)("em",{parentName:"td"},"models/pytorch-${model_name}/fp16_inference_throughput"),"{percentile}"),(0,l.kt)("td",{parentName:"tr",align:null},"throughput (samples/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"The {percentile}th percentile inference throughput with half precision.")))))}u.isMDXComponent=!0}}]);