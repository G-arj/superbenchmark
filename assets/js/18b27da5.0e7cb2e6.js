(self.webpackChunksuperbench_website=self.webpackChunksuperbench_website||[]).push([[712],{3905:function(t,e,a){"use strict";a.d(e,{Zo:function(){return p},kt:function(){return k}});var n=a(7294);function r(t,e,a){return e in t?Object.defineProperty(t,e,{value:a,enumerable:!0,configurable:!0,writable:!0}):t[e]=a,t}function l(t,e){var a=Object.keys(t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(t);e&&(n=n.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),a.push.apply(a,n)}return a}function i(t){for(var e=1;e<arguments.length;e++){var a=null!=arguments[e]?arguments[e]:{};e%2?l(Object(a),!0).forEach((function(e){r(t,e,a[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(a,e))}))}return t}function m(t,e){if(null==t)return{};var a,n,r=function(t,e){if(null==t)return{};var a,n,r={},l=Object.keys(t);for(n=0;n<l.length;n++)a=l[n],e.indexOf(a)>=0||(r[a]=t[a]);return r}(t,e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(t);for(n=0;n<l.length;n++)a=l[n],e.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(t,a)&&(r[a]=t[a])}return r}var o=n.createContext({}),d=function(t){var e=n.useContext(o),a=e;return t&&(a="function"==typeof t?t(e):i(i({},e),t)),a},p=function(t){var e=d(t.components);return n.createElement(o.Provider,{value:e},t.children)},c={inlineCode:"code",wrapper:function(t){var e=t.children;return n.createElement(n.Fragment,{},e)}},u=n.forwardRef((function(t,e){var a=t.components,r=t.mdxType,l=t.originalType,o=t.parentName,p=m(t,["components","mdxType","originalType","parentName"]),u=d(a),k=r,s=u["".concat(o,".").concat(k)]||u[k]||c[k]||l;return a?n.createElement(s,i(i({ref:e},p),{},{components:a})):n.createElement(s,i({ref:e},p))}));function k(t,e){var a=arguments,r=e&&e.mdxType;if("string"==typeof t||r){var l=a.length,i=new Array(l);i[0]=u;var m={};for(var o in e)hasOwnProperty.call(e,o)&&(m[o]=e[o]);m.originalType=t,m.mdxType="string"==typeof t?t:r,i[1]=m;for(var d=2;d<l;d++)i[d]=a[d];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},485:function(t,e,a){"use strict";a.r(e),a.d(e,{frontMatter:function(){return m},contentTitle:function(){return o},metadata:function(){return d},toc:function(){return p},default:function(){return u}});var n=a(2122),r=a(9756),l=(a(7294),a(3905)),i=["components"],m={id:"micro-benchmarks"},o="Micro Benchmarks",d={unversionedId:"user-tutorial/benchmarks/micro-benchmarks",id:"user-tutorial/benchmarks/micro-benchmarks",isDocsHomePage:!1,title:"Micro Benchmarks",description:"Computation Benchmarks",source:"@site/../docs/user-tutorial/benchmarks/micro-benchmarks.md",sourceDirName:"user-tutorial/benchmarks",slug:"/user-tutorial/benchmarks/micro-benchmarks",permalink:"/superbenchmark/docs/user-tutorial/benchmarks/micro-benchmarks",editUrl:"https://github.com/microsoft/superbenchmark/edit/main/website/../docs/user-tutorial/benchmarks/micro-benchmarks.md",version:"current",frontMatter:{id:"micro-benchmarks"},sidebar:"docs",previous:{title:"Run SuperBench",permalink:"/superbenchmark/docs/getting-started/run-superbench"},next:{title:"Model Benchmarks",permalink:"/superbenchmark/docs/user-tutorial/benchmarks/model-benchmarks"}},p=[{value:"Computation Benchmarks",id:"computation-benchmarks",children:[{value:"<code>kernel-launch</code>",id:"kernel-launch",children:[]},{value:"<code>gemm-flops</code>",id:"gemm-flops",children:[]},{value:"<code>matmul</code>",id:"matmul",children:[]},{value:"<code>cublas-function</code>",id:"cublas-function",children:[]},{value:"<code>cudnn-function</code>",id:"cudnn-function",children:[]}]},{value:"Communication Benchmarks",id:"communication-benchmarks",children:[{value:"<code>mem-bw</code>",id:"mem-bw",children:[]},{value:"<code>gpu-sm-copy-bw</code>",id:"gpu-sm-copy-bw",children:[]},{value:"<code>ib-loopback</code>",id:"ib-loopback",children:[]},{value:"<code>nccl-bw</code> / <code>rccl-bw</code>",id:"nccl-bw--rccl-bw",children:[]}]},{value:"Computation-communication Benchmarks",id:"computation-communication-benchmarks",children:[{value:"<code>computation-communication-overlap</code>",id:"computation-communication-overlap",children:[]},{value:"<code>sharding-matmul</code>",id:"sharding-matmul",children:[]}]},{value:"Storage Benchmarks",id:"storage-benchmarks",children:[{value:"<code>disk-benchmark</code>",id:"disk-benchmark",children:[]}]}],c={toc:p};function u(t){var e=t.components,a=(0,r.Z)(t,i);return(0,l.kt)("wrapper",(0,n.Z)({},c,a,{components:e,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"micro-benchmarks"},"Micro Benchmarks"),(0,l.kt)("h2",{id:"computation-benchmarks"},"Computation Benchmarks"),(0,l.kt)("h3",{id:"kernel-launch"},(0,l.kt)("inlineCode",{parentName:"h3"},"kernel-launch")),(0,l.kt)("h4",{id:"introduction"},"Introduction"),(0,l.kt)("p",null,"Measure GPU kernel launch latency,\nwhich is defined as the time range from the beginning of the launch API call to the beginning of the kernel execution."),(0,l.kt)("h4",{id:"metrics"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"kernel-launch/event_overhead"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"Launch latency measured in GPU time.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"kernel-launch/wall_overhead"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"Launch latency measured in CPU time.")))),(0,l.kt)("h3",{id:"gemm-flops"},(0,l.kt)("inlineCode",{parentName:"h3"},"gemm-flops")),(0,l.kt)("h4",{id:"introduction-1"},"Introduction"),(0,l.kt)("p",null,"Measure the GPU GEMM FLOPS for different float and int data types, with or without Tensor Core (XDLOPS),\nperformed by NVIDIA ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/NVIDIA/cutlass/tree/ccb697bac77fcc898e9c897b2c90aa5b60ac72fb"},"cutlass"),"\nor AMD ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/ROCmSoftwarePlatform/rocBLAS/tree/develop/clients/benchmarks"},"rocblas-bench"),"."),(0,l.kt)("h4",{id:"metrics-1"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/FP64"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM float64 peak FLOPS.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/FP32"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM float32 peak FLOPS.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/FP16"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM float16 peak FLOPS.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/FP64_TC"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM float64 peak FLOPS with NVIDIA Tensor Core.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/TF32_TC"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM tensor-float32 peak FLOPS with NVIDIA Tensor Core.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/FP16_TC"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM float16 peak FLOPS with NVIDIA Tensor Core.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/BF16_TC"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM bfloat16 peak FLOPS with NVIDIA Tensor Core.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/INT8_TC"),(0,l.kt)("td",{parentName:"tr",align:null},"IOPS (GIOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM int8 peak IOPS with NVIDIA Tensor Core.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/INT4_TC"),(0,l.kt)("td",{parentName:"tr",align:null},"IOPS (GIOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM int4 peak IOPS with NVIDIA Tensor Core.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/FP32_xDLOPS"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM tensor-float32 peak FLOPS with AMD XDLOPS.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/FP16_xDLOPS"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM float16 peak FLOPS with AMD XDLOPS.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/BF16_xDLOPS"),(0,l.kt)("td",{parentName:"tr",align:null},"FLOPS (GFLOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM bfloat16 peak FLOPS with AMD XDLOPS.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gemm-flops/INT8_xDLOPS"),(0,l.kt)("td",{parentName:"tr",align:null},"IOPS (GIOPS)"),(0,l.kt)("td",{parentName:"tr",align:null},"GEMM int8 peak IOPS with AMD XDLOPS.")))),(0,l.kt)("h3",{id:"matmul"},(0,l.kt)("inlineCode",{parentName:"h3"},"matmul")),(0,l.kt)("h4",{id:"introduction-2"},"Introduction"),(0,l.kt)("p",null,"Large scale matmul operation using ",(0,l.kt)("inlineCode",{parentName:"p"},"torch.matmul")," with one GPU."),(0,l.kt)("h4",{id:"metrics-2"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"pytorch-matmul/nosharding"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"Time of pure matmul operation.")))),(0,l.kt)("h3",{id:"cublas-function"},(0,l.kt)("inlineCode",{parentName:"h3"},"cublas-function")),(0,l.kt)("p",null,"TODO"),(0,l.kt)("h3",{id:"cudnn-function"},(0,l.kt)("inlineCode",{parentName:"h3"},"cudnn-function")),(0,l.kt)("p",null,"TODO"),(0,l.kt)("h2",{id:"communication-benchmarks"},"Communication Benchmarks"),(0,l.kt)("h3",{id:"mem-bw"},(0,l.kt)("inlineCode",{parentName:"h3"},"mem-bw")),(0,l.kt)("h4",{id:"introduction-3"},"Introduction"),(0,l.kt)("p",null,"Measure the memory copy bandwidth across PCI-e and memory copy bandwidth between GPUs,\nperformed by ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/NVIDIA/cuda-samples/tree/master/Samples/bandwidthTest"},"NVIDIA"),"\nor ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/ROCm-Developer-Tools/HIP/tree/master/samples/1_Utils/hipBusBandwidth"},"AMD")," bandwidth test tool."),(0,l.kt)("h4",{id:"metrics-3"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"mem-bw/H2D_Mem_BW"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (GB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"Host to device copy bandwidth.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"mem-bw/D2H_Mem_BW"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (GB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"Device to host copy bandwidth.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"mem-bw/D2D_Mem_BW"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (GB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"Device to device copy bandwidth.")))),(0,l.kt)("h3",{id:"gpu-sm-copy-bw"},(0,l.kt)("inlineCode",{parentName:"h3"},"gpu-sm-copy-bw")),(0,l.kt)("p",null,"Measure the memory copy bandwidth across PCI-e and memory copy bandwidth between GPUs, initialized by GPU SM."),(0,l.kt)("h4",{id:"metrics-4"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpu-sm-copy-bw/htod"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (GB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"Host to device copy bandwidth initialized by GPU SM.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"gpu-sm-copy-bw/dtoh"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (GB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"Device to host copy bandwidth initialized by GPU SM.")))),(0,l.kt)("h3",{id:"ib-loopback"},(0,l.kt)("inlineCode",{parentName:"h3"},"ib-loopback")),(0,l.kt)("h4",{id:"introduction-4"},"Introduction"),(0,l.kt)("p",null,"Measure the InfiniBand loopback verbs bandwidth, performed by\n",(0,l.kt)("a",{parentName:"p",href:"https://github.com/linux-rdma/perftest/tree/7504ce48ac396a02f4d00de359257b2cb8458f06"},"OFED performance tests"),"."),(0,l.kt)("h4",{id:"metrics-5"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"ib-loopback/IB","_","write","_","${msg","_","size}","_","Avg_${ib_dev}"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (MB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"InfiniBand loopback write bandwidth with given message size.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"ib-loopback/IB","_","read","_","${msg","_","size}","_","Avg_${ib_dev}"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (MB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"InfiniBand loopback read bandwidth with given message size.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"ib-loopback/IB","_","send","_","${msg","_","size}","_","Avg_${ib_dev}"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (MB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"InfiniBand loopback send bandwidth with given message size.")))),(0,l.kt)("h3",{id:"nccl-bw--rccl-bw"},(0,l.kt)("inlineCode",{parentName:"h3"},"nccl-bw")," / ",(0,l.kt)("inlineCode",{parentName:"h3"},"rccl-bw")),(0,l.kt)("h4",{id:"introduction-5"},"Introduction"),(0,l.kt)("p",null,"Measure the performance of NCCL/RCCL operations,\nperformed by ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/NVIDIA/nccl-tests/tree/44df0bf010dcc95e840ca0fb7466c67cff3f1f0f"},"nccl-tests"),"\nor ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/ROCmSoftwarePlatform/rccl-tests/tree/dc1ad4853d7ec738387d42a75a58a98d7af00c7b"},"rccl-tests"),".\nSupport the following operations currently: allreduce, allgather, broadcast, reduce, reducescatter, alltoall."),(0,l.kt)("h4",{id:"metrics-6"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"nccl-bw/${operation}_${msg_size}_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (us)"),(0,l.kt)("td",{parentName:"tr",align:null},"NCCL operation lantency with given message size.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"nccl-bw/${operation}_${msg_size}_algbw"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (GB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"NCCL operation algorithm bandwidth with given message size.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"nccl-bw/${operation}_${msg_size}_busbw"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (GB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"NCCL operation bus bandwidth with given message size.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"rccl-bw/${operation}_${msg_size}_time"),(0,l.kt)("td",{parentName:"tr",align:null},"time (us)"),(0,l.kt)("td",{parentName:"tr",align:null},"RCCL operation lantency with given message size.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"rccl-bw/${operation}_${msg_size}_algbw"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (GB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"RCCL operation algorithm bandwidth with given message size.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"rccl-bw/${operation}_${msg_size}_busbw"),(0,l.kt)("td",{parentName:"tr",align:null},"bandwidth (GB/s)"),(0,l.kt)("td",{parentName:"tr",align:null},"RCCL operation bus bandwidth with given message size.")))),(0,l.kt)("h2",{id:"computation-communication-benchmarks"},"Computation-communication Benchmarks"),(0,l.kt)("h3",{id:"computation-communication-overlap"},(0,l.kt)("inlineCode",{parentName:"h3"},"computation-communication-overlap")),(0,l.kt)("h4",{id:"introduction-6"},"Introduction"),(0,l.kt)("p",null,"Test the performance of single node when communication and computation overlap."),(0,l.kt)("h4",{id:"metrics-7"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"pytorch-computation-communication-overlap/mul_cost"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"Time of communication and mul kernel computation overlap.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"pytorch-computation-communication-overlap/matmul_cost"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"Time of communication and matmul kernel computation overlap.")))),(0,l.kt)("h4",{id:""}),(0,l.kt)("h3",{id:"sharding-matmul"},(0,l.kt)("inlineCode",{parentName:"h3"},"sharding-matmul")),(0,l.kt)("h4",{id:"introduction-7"},"Introduction"),(0,l.kt)("p",null,"Test the performance of large scale matmul operation with multiple GPUs:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"allreduce: Each GPU will calculate part of the MM calculation, and use AllReduce to merge all data into one tensor."),(0,l.kt)("li",{parentName:"ul"},"allgather: Each GPU will calculate part of the MM calculation, and use AllGather + Concat to merge all data into one tensor.")),(0,l.kt)("h4",{id:"metrics-8"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"pytorch-sharding-matmul/allreduce"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"Time of sharding matmul using allreduce.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"pytorch-sharding-matmul/allgather"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ms)"),(0,l.kt)("td",{parentName:"tr",align:null},"Time of sharding matmul using allgather.")))),(0,l.kt)("h2",{id:"storage-benchmarks"},"Storage Benchmarks"),(0,l.kt)("h3",{id:"disk-benchmark"},(0,l.kt)("inlineCode",{parentName:"h3"},"disk-benchmark")),(0,l.kt)("h4",{id:"introduction-8"},"Introduction"),(0,l.kt)("p",null,"Measure the disk performance through ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/axboe/fio/tree/0313e938c9c8bb37d71dade239f1f5326677b079"},"FIO"),"."),(0,l.kt)("h4",{id:"metrics-9"},"Metrics"),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Name"),(0,l.kt)("th",{parentName:"tr",align:null},"Unit"),(0,l.kt)("th",{parentName:"tr",align:null},"Description"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"disk-benchmark/${disk_name}_rand_read_write_bs"),(0,l.kt)("td",{parentName:"tr",align:null},"size (bytes)"),(0,l.kt)("td",{parentName:"tr",align:null},"Disk random read write block size.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"disk-benchmark/${disk_name}_rand_read_write_read_iops"),(0,l.kt)("td",{parentName:"tr",align:null},"IOPS"),(0,l.kt)("td",{parentName:"tr",align:null},"Disk random read write read IOPS.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"disk-benchmark/${disk_name}_rand_read_write_read_lat_ns_95.000000"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ns)"),(0,l.kt)("td",{parentName:"tr",align:null},"Disk random read write read latency in 95.0 percentile.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"disk-benchmark/${disk_name}_rand_read_write_read_lat_ns_99.000000"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ns)"),(0,l.kt)("td",{parentName:"tr",align:null},"Disk random read write read latency in 99.0 percentile.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"disk-benchmark/${disk_name}_rand_read_write_read_lat_ns_99.900000"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ns)"),(0,l.kt)("td",{parentName:"tr",align:null},"Disk random read write read latency in 99.9 percentile.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"disk-benchmark/${disk_name}_rand_read_write_write_iops"),(0,l.kt)("td",{parentName:"tr",align:null},"IOPS"),(0,l.kt)("td",{parentName:"tr",align:null},"Disk random read write write IOPS.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"disk-benchmark/${disk_name}_rand_read_write_write_lat_ns_95.000000"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ns)"),(0,l.kt)("td",{parentName:"tr",align:null},"Disk random read write write latency in 95.0 percentile.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"disk-benchmark/${disk_name}_rand_read_write_write_lat_ns_99.000000"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ns)"),(0,l.kt)("td",{parentName:"tr",align:null},"Disk random read write write latency in 99.0 percentile.")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"disk-benchmark/${disk_name}_rand_read_write_write_lat_ns_99.900000"),(0,l.kt)("td",{parentName:"tr",align:null},"time (ns)"),(0,l.kt)("td",{parentName:"tr",align:null},"Disk random read write write latency in 99.9 percentile.")))))}u.isMDXComponent=!0}}]);