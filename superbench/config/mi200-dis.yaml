# SuperBench Config
#
# Server:
#   - Product: Hayabusa

version: v0.3
superbench:
  enable: ['densenet_models','gpt_models','bert_models','lstm_models','vgg_models','resnet_models']
  var:
    default_local_mode: &default_local_mode
      enable: true
      modes:
        - name: local
          proc_num: 1
          prefix: HIP_VISIBLE_DEVICES=1
          parallel: no
    default_pytorch_mode: &default_pytorch_mode
      enable: true
      modes:
        - name: torch.distributed
          proc_num: 16
          node_num: 2
      frameworks:
        - pytorch
    common_model_config: &common_model_config
      duration: 0
      num_warmup: 64
      num_steps: 100
      sample_count: 8192
      batch_size: 32
      precision:
        - float32
        - float16
      model_action:
        - train
      pin_memory: yes
  benchmarks:
    kernel-launch:
      <<: *default_local_mode
    rccl-bw:
      enable: true
      modes:
        - name: mpi
          proc_num: 16
          env:
            NCCL_IB_GDR_LEVEL: 5
            HSA_ENABLE_SDMA: 0
            LD_LIBRARY_PATH: /root/rccl-rdma-sharp-plugins/src/.libs 
            NCCL_MIN_NCHANNELS: 16 
            NCCL_NET_GDR_READ: 1
            NCCL_IB_PCI_RELAXED_ORDERING: 1
      parameters:
        maxbytes: 1G
        operation: allreduce
        ngpus: 1
    mem-bw:
      enable: true
      modes:
        - name: local
          proc_num: 16
          prefix: HIP_VISIBLE_DEVICES={proc_rank} HSA_ENABLE_SDMA=0
          parallel: no
    gemm-flops:
      <<: *default_local_mode
      parameters:
        m: 7680
        n: 8192
        k: 8192
    ib-loopback:
      enable: true
      modes:
        - name: local
          proc_num: 32
          prefix: PROC_RANK={proc_rank} IB_DEVICES=0,1,2,3,4,5,6,7,0,1,2,3,4,5,6,7,0,1,2,3,4,5,6,7,0,1,2,3,4,5,6,7 numactl -N $(({proc_rank}/8)) -m $(({proc_rank}/8))
          parallel: no
    disk-benchmark:
      enable: false
      modes:
        - name: local
          proc_num: 1
          parallel: no
      parameters:
        block_devices: []
    gpu-copy-bw:
      enable: true
      modes:
        - name: local
          parallel: no
      parameters:
        mem_type:
          - htod
          - dtoh
          - dtod
        copy_type:
          - sm
          - dma
    gpt_models:
      <<: *default_pytorch_mode
      models:
        - gpt2-large
      parameters:
        <<: *common_model_config
        batch_size: 8
        seq_len: 224
    bert_models:
      <<: *default_pytorch_mode
      models:
        - bert-base
        - bert-large
      parameters:
        <<: *common_model_config
        seq_len: 224
    lstm_models:
      <<: *default_pytorch_mode
      models:
        - lstm
      parameters:
        <<: *common_model_config
        batch_size: 224
        input_size: 224
        hidden_size: 1000
        seq_len: 32
        pin_memory: no
    resnet_models:
      <<: *default_pytorch_mode
      models:
        - resnet50
        - resnet101
        - resnet152
      parameters:
        <<: *common_model_config
        pin_memory: no
    densenet_models:
      <<: *default_pytorch_mode
      models:
        - densenet169
        - densenet201
      parameters:
        <<: *common_model_config
        pin_memory: no
    vgg_models:
      <<: *default_pytorch_mode
      models:
        - vgg11
        - vgg13
        - vgg16
        - vgg19
      parameters:
        <<: *common_model_config
        pin_memory: no

